/// ğŸš€ Nueva API Ultra-Limpia para AI Providers
library;

import 'package:ai_providers/ai_providers.dart';

import 'capabilities/audio_generation_service.dart';
import 'capabilities/audio_transcription_service.dart';
import 'capabilities/image_analysis_service.dart';
import 'capabilities/image_generation_service.dart';
import 'capabilities/text_generation_service.dart';
import 'core/ai_provider_manager.dart';
import 'core/config_loader.dart';
import 'models/ai_user_preferences.dart';
import 'utils/logger.dart';

/// ğŸ¯ Clase AI - API Principal Ultra-Directa
///
/// Arquitectura estratificada:
/// ğŸ® MÃ©todos directos: AI.text(), AI.image(), AI.vision(), AI.speak(), AI.listen() (con detecciÃ³n de silencio), AI.transcribe() (capability automÃ¡tico)
/// ğŸ”§ MÃ©todo universal: AI.generate() (capability manual)
class AI {
  // Singleton del manager interno (oculto del usuario)
  static AIProviderManager get _manager => AIProviderManager.instance;

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // ğŸ® MÃ‰TODOS DIRECTOS (Capability AutomÃ¡tico - SÃºper FÃ¡cil)
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  /// ğŸ’¬ GeneraciÃ³n de texto/conversaciÃ³n
  /// Capability automÃ¡tico: textGeneration
  ///
  /// [context] - Opcional. Si no se proporciona, usa configuraciÃ³n por defecto
  static Future<AIResponse> text(final String message,
      [final AISystemPrompt? systemPrompt]) async {
    AILogger.d('[AI] ğŸ’¬ text() - generating response: ${message.length} chars');
    await _manager.initialize();

    // Delegar a TextGenerationService (nueva arquitectura)
    return TextGenerationService.instance.generate(message, systemPrompt);
  }

  /// ğŸ–¼ï¸ GeneraciÃ³n de imÃ¡genes
  /// Capability automÃ¡tico: imageGeneration
  ///
  /// Siempre devuelve tanto imageBase64 como imageFileName (si se guarda en cachÃ©)
  /// para mÃ¡xima flexibilidad del usuario.
  ///
  /// **Ejemplo bÃ¡sico:**
  /// ```dart
  /// final image = await AI.image('Robot pintando un mural retro futurista');
  /// ```
  ///
  /// **Ejemplo con parÃ¡metros avanzados:**
  /// ```dart
  /// final logo = await AI.image(
  ///   'Mascota robÃ³tica con estilo pixel art',
  ///   null,
  ///   const AiImageParams(
  ///     aspectRatio: AiImageAspectRatio.landscape,
  ///     quality: AiImageQuality.high,
  ///     format: AiImageFormat.png,
  ///     background: AiImageBackground.transparent,
  ///     fidelity: AiImageFidelity.high,
  ///     seed: 'logo-v1',
  ///   ),
  /// );
  /// ```
  ///
  /// [prompt] - DescripciÃ³n de la imagen a generar
  /// [context] - Opcional. Si no se proporciona, usa configuraciÃ³n por defecto
  /// [imageParams] - Opcional. ParÃ¡metros especÃ­ficos de imagen. Ver [AiImageParams] para detalles completos
  static Future<AIResponse> image(
    final String prompt, [
    final AISystemPrompt? systemPrompt,
    final AiImageParams? imageParams,
  ]) async {
    AILogger.d(
        '[AI] ğŸ–¼ï¸ image() - generating image: ${prompt.length} chars${imageParams != null ? ', params: $imageParams' : ''}');
    await _manager.initialize();

    // Delegar siempre a ImageGenerationService que maneja todos los casos
    return ImageGenerationService.instance
        .generateImage(prompt, systemPrompt, true, imageParams);
  }

  /// ğŸ‘ï¸ AnÃ¡lisis de imagen/visiÃ³n
  /// Capability automÃ¡tico: imageAnalysis
  ///
  /// [prompt] - Opcional. Si no se proporciona, usa 'Describe esta imagen'
  /// [context] - Opcional. Si no se proporciona, usa configuraciÃ³n por defecto
  static Future<AIResponse> vision(
    final String imageBase64, [
    final String? prompt,
    final AISystemPrompt? systemPrompt,
    final String? imageMimeType,
  ]) async {
    AILogger.d('[AI] ğŸ‘ï¸ vision() - analyzing image');
    await _manager.initialize();

    // Delegar a ImageAnalysisService (nueva arquitectura)
    return ImageAnalysisService.instance.analyze(
      imageBase64,
      prompt,
      systemPrompt,
      imageMimeType,
    );
  }

  /// ğŸ¤ SÃ­ntesis de voz/TTS/audio
  /// Capability automÃ¡tico: audioGeneration
  ///
  /// Siempre devuelve tanto audioBase64 como audioFileName (guardado en cachÃ©)
  /// para mÃ¡xima flexibilidad del usuario.
  ///
  /// **Ejemplo bÃ¡sico:**
  /// ```dart
  /// final audio = await AI.speak('Hola mundo');
  /// ```
  ///
  /// **Ejemplo con parÃ¡metros avanzados:**
  /// ```dart
  /// final audio = await AI.speak(
  ///   'Buenos dÃ­as, Â¿cÃ³mo estÃ¡s?',
  ///   AiAudioParams(
  ///     speed: 1.2,
  ///     audioFormat: AiAudioFormat.wav,
  ///     language: 'es',
  ///     accent: 'espaÃ±ol con acento japonÃ©s',
  ///     emotion: 'susurrando pero asustada como si acabaras de despertar',
  ///   ),
  ///   play: true,  // Reproduce automÃ¡ticamente
  /// );
  /// ```
  ///
  /// [text] - Texto a sintetizar
  /// [audioParams] - ParÃ¡metros tipados de audio (velocidad, formato, idioma, acento, emociÃ³n)
  /// [play] - Si es true, reproduce el audio automÃ¡ticamente despuÃ©s de generarlo
  static Future<AIResponse> speak(
    final String text, [
    final AiAudioParams? audioParams,
    final bool play = false,
  ]) async {
    AILogger.d(
        '[AI] ğŸ¤ speak() - generating audio: ${text.length} chars, play: $play${audioParams != null ? ', params: $audioParams' : ''}');
    await _manager.initialize();

    // Delegar toda la lÃ³gica al AudioGenerationService - siempre guarda en cachÃ©
    return AudioGenerationService.instance.synthesize(text, audioParams, play);
  }

  /// ğŸ§ Escuchar/grabar y transcribir audio automÃ¡ticamente
  /// Capability automÃ¡tico: audioTranscription
  ///
  /// **CON autoStop=true (default):** Graba hasta detectar silencio y retorna AIResponse
  /// **CON autoStop=false:** Solo inicia grabaciÃ³n y retorna null (usar AI.stopListen() para resultado)
  ///
  /// **Ejemplos:**
  /// ```dart
  /// // Auto-detecciÃ³n
  /// final result = await AI.listen();
  /// if (result != null) print(result.text);
  ///
  /// // Control manual
  /// await AI.listen(autoStop: false); // retorna null
  /// final result = await AI.stopListen(); // retorna AIResponse
  /// ```
  ///
  /// [duration] - DuraciÃ³n mÃ¡xima de grabaciÃ³n (null = ilimitado hasta silencio)
  /// [silenceTimeout] - Tiempo de silencio para auto-detenciÃ³n (default: 2s)
  /// [autoStop] - Detener automÃ¡ticamente al detectar silencio (default: true)
  /// [systemPrompt] - Instrucciones del sistema para la transcripciÃ³n
  ///
  /// **Retorna:** AIResponse con transcripciÃ³n si autoStop=true, null si autoStop=false
  static Future<AIResponse?> listen({
    final Duration? duration,
    final Duration silenceTimeout = const Duration(seconds: 2),
    final bool autoStop = true,
    final AISystemPrompt? systemPrompt,
  }) async {
    // Log de configuraciÃ³n inteligente
    final configLog = duration != null
        ? 'fixed duration: ${duration.inSeconds}s'
        : autoStop
            ? 'auto-stop on silence (${silenceTimeout.inSeconds}s timeout)'
            : 'manual stop only';

    AILogger.d('[AI] ğŸ§ listen() - recording with $configLog');
    await _manager.initialize();

    // Delegar toda la lÃ³gica avanzada al AudioTranscriptionService
    final result = await AudioTranscriptionService.instance.recordAndTranscribe(
      duration: duration,
      silenceTimeout: silenceTimeout,
      autoStop: autoStop,
      systemPrompt: systemPrompt,
    );

    // Retornar AIResponse completo (incluye audio grabado)
    return result;
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // ğŸ›ï¸ CONTROL Y UTILIDADES (MÃ©todos de Control y Funciones Avanzadas)
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  /// ğŸ›‘ Detener reproducciÃ³n de audio/TTS
  /// Detiene cualquier audio que estÃ© siendo reproducido actualmente
  static Future<bool> stopSpeak() async {
    AILogger.d('[AI] ğŸ›‘ stopSpeak() - stopping audio playback');
    await _manager.initialize();

    // Delegar al AudioGenerationService
    return AudioGenerationService.instance.stopPlayback();
  }

  /// â¸ï¸ Pausar reproducciÃ³n de audio/TTS
  /// Pausa el audio que estÃ¡ siendo reproducido actualmente
  static Future<bool> pauseSpeak() async {
    AILogger.d('[AI] â¸ï¸ pauseSpeak() - pausing audio playback');
    await _manager.initialize();

    // Delegar al AudioGenerationService
    return AudioGenerationService.instance.pausePlayback();
  }

  /// ğŸ›‘ Detener grabaciÃ³n de audio en curso
  /// Detiene la grabaciÃ³n actual y retorna AIResponse con transcripciÃ³n y audio grabado
  ///
  /// **Devuelve:** AIResponse con `text` (transcripciÃ³n) y `audio` (URL + base64 del archivo grabado)
  static Future<AIResponse?> stopListen() async {
    AILogger.d('[AI] ğŸ›‘ stopListen() - stopping audio recording');
    await _manager.initialize();

    // Delegar al AudioTranscriptionService
    return AudioTranscriptionService.instance.stopRecording();
  }

  /// ğŸ§ Transcribir audio existente/STT
  /// Capability automÃ¡tico: audioTranscription
  ///
  /// [audioBase64] - Audio en formato base64 a transcribir
  /// [context] - Instrucciones del sistema para la transcripciÃ³n
  static Future<AIResponse> transcribe(final String audioBase64,
      [final AISystemPrompt? systemPrompt]) async {
    AILogger.d('[AI] ğŸ§ transcribe() - transcribing audio');
    await _manager.initialize();

    // Delegar a AudioTranscriptionService (nueva arquitectura)
    return AudioTranscriptionService.instance
        .transcribe(audioBase64, systemPrompt);
  }

  /// ğŸ’¬ Crear conversaciÃ³n hÃ­brida con streams TTS/STT/respuesta
  /// Permite conversaciones en tiempo real con transcripciÃ³n y sÃ­ntesis automÃ¡tica
  static HybridConversationService createConversation() {
    AILogger.d('[AI] ğŸ’¬ createConversation() - creating hybrid conversation');
    return HybridConversationService();
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // ğŸ”§ MÃ‰TODO UNIVERSAL (Capability Manual - Casos Complejos)
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  /// ğŸ”§ MÃ©todo universal para casos complejos
  /// Permite especificar capability manualmente cuando necesites control total
  static Future<AIResponse> generate({
    required final String message,
    required final AISystemPrompt systemPrompt,
    required final AICapability capability,
    final String? imageBase64,
    final String? imageMimeType,
  }) async {
    AILogger.d('[AI] ğŸ”§ generate() - capability: ${capability.name}');
    await _manager.initialize();
    return _manager.sendMessage(
      message: message,
      systemPrompt: systemPrompt,
      capability: capability,
      imageBase64: imageBase64,
      imageMimeType: imageMimeType,
    );
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // ğŸ› ï¸ UTILIDADES Y ESTADO
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  /// âš¡ InicializaciÃ³n del sistema AI (automÃ¡tica en primer uso de API)
  /// Carga la configuraciÃ³n desde assets y registra todos los providers
  static Future<void> initialize({final AIInitConfig? config}) async {
    AILogger.d('[AI] âš¡ initialize() - initializing AI system');
    await _manager.initialize(config: config);
  }

  /// ğŸ“Š Estado de inicializaciÃ³n
  static bool get isInitialized => _manager.isInitialized;

  /// ğŸ” InformaciÃ³n de debug
  static String get debugInfo {
    return '''
AI API Status:
- Initialized: ${_manager.isInitialized}
- Providers loaded: ${_manager.providers.length}
- Available capabilities: ${AICapability.values.map((final c) => c.name).join(', ')}
''';
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // âš™ï¸ CONFIGURATION APIs
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  /// ğŸ¯ Obtiene el modelo actualmente configurado para una capability especÃ­fica
  /// Considera tanto el modelo guardado en preferencias como el del YAML
  static Future<String?> getCurrentModel(final AICapability capability) async {
    await _manager.initialize();

    // Primero intentar obtener el modelo guardado en preferencias
    final savedModel =
        await _manager.getSavedModelForCapabilityIfSupported(capability);
    if (savedModel != null && savedModel.isNotEmpty) {
      return savedModel;
    }

    // Si no hay modelo guardado, usar el modelo por defecto del YAML
    return await _manager.getDefaultModelForCapability(capability);
  }

  /// Get the default model for a specific provider (text generation)
  static Future<String?> getDefaultModelForProvider(
      final String providerId, final AICapability capability) async {
    await _manager.initialize();
    return await _manager.getDefaultModelForProvider(providerId, capability);
  }

  /// ğŸ¯ Establece proveedor y modelo para una capacidad especÃ­fica
  /// API UNIFICADA que reemplaza setSelectedModel() y setSelectedAudioProvider()
  /// Persiste la selecciÃ³n para que se use automÃ¡ticamente en prÃ³ximas sesiones
  static Future<void> setModel(
    final String providerId,
    final String modelId,
    final AICapability capability,
  ) async {
    await _manager.initialize();
    await _manager.setModel(providerId, modelId, capability);
  }

  /// ğŸ§¹ Limpia la cachÃ© de texto en memoria y devuelve cuÃ¡ntas entradas fueron eliminadas
  static Future<int> clearTextCache() async {
    await _manager.initialize();
    return _manager.clearTextCache();
  }

  /// ğŸ§¹ Limpia la cachÃ© de audio en disco y devuelve cuÃ¡ntos archivos fueron eliminados
  static Future<int> clearAudioCache() async {
    await _manager.initialize();
    return _manager.clearAudioCache();
  }

  /// ğŸ§¹ Limpia la cachÃ© de imÃ¡genes en disco y devuelve cuÃ¡ntos archivos fueron eliminados
  static Future<int> clearImageCache() async {
    await _manager.initialize();
    return _manager.clearImageCache();
  }

  /// ğŸ§¹ Limpia la cachÃ© de modelos persistidos y devuelve cuÃ¡ntos archivos fueron eliminados
  static Future<int> clearModelsCache() async {
    await _manager.initialize();
    return _manager.clearModelsCache();
  }

  /// ğŸ¤ Establece la voz seleccionada para un proveedor especÃ­fico
  static Future<void> setSelectedVoiceForProvider(
      final String provider, final String voice) async {
    await _manager.initialize();
    await _manager.setSelectedVoiceForProvider(provider, voice);
  }

  /// ğŸ¤ Obtiene la voz por defecto para un proveedor especÃ­fico
  /// Usado por PrefsUtils para obtener valores por defecto de configuraciÃ³n
  static String? getDefaultVoiceForProvider(final String providerId) {
    return AIProviderConfigLoader.getDefaultVoiceForProvider(providerId);
  }

  /// ğŸ¯ Obtiene todos los modelos disponibles de un proveedor especÃ­fico
  static Future<List<String>> getAvailableModels(
      final String providerId) async {
    await _manager.initialize();
    try {
      return await _manager.getAvailableModels(providerId);
    } on Exception catch (e) {
      AILogger.w('Error getting models for provider $providerId: $e');
      return [];
    }
  }

  /// ğŸ¤ Obtiene la voz configurada para un proveedor especÃ­fico
  static Future<String?> getCurrentVoiceForProvider(
      final String providerId) async {
    await _manager.initialize();
    try {
      // Try to get saved voice from preferences
      final savedVoice = await _manager.getSavedVoiceForProvider(providerId);
      if (savedVoice != null && savedVoice.isNotEmpty) {
        return savedVoice;
      }

      // Fallback to default voice from configuration
      return getDefaultVoiceForProvider(providerId);
    } on Exception catch (e) {
      AILogger.w('Error getting current voice for provider $providerId: $e');
      return getDefaultVoiceForProvider(providerId);
    }
  }

  /// ğŸ›ï¸ Obtiene el proveedor actualmente activo para una capability
  static Future<String?> getCurrentProvider(
      final AICapability capability) async {
    await _manager.initialize();
    try {
      final savedConfig =
          await AIUserPreferences.getConfigForCapability(capability);
      if (savedConfig != null) {
        final supportedProviders =
            _manager.getProvidersByCapability(capability);
        if (supportedProviders.contains(savedConfig.provider)) {
          return savedConfig.provider;
        }
      }
    } on Exception catch (e) {
      AILogger.w(
          '[AI] getCurrentProvider: failed to read user preferences for ${capability.name}: $e');
    }

    return _manager.getPrimaryProvider(capability);
  }

  /// ğŸ›ï¸ Obtiene todos los proveedores disponibles con informaciÃ³n rica para una capability
  static List<AIProvider> getAvailableProviders(final AICapability capability) {
    if (!_manager.isInitialized || _manager.config == null) return [];

    // Get provider IDs that support the capability in fallback order
    final providerIds = _manager.getProvidersForCapabilityInOrder(capability);

    // Convert provider IDs to AIProvider objects from YAML config
    return providerIds.map((final providerId) {
      final providerConfig = _manager.config!.aiProviders[providerId];
      if (providerConfig == null) {
        throw StateError(
          'Provider "$providerId" is initialized but not found in configuration. '
          'This indicates a configuration mismatch - check ai_providers_config.yaml',
        );
      }

      // Use the new AIProvider.fromConfig factory method
      return AIProvider.fromConfig(
        id: providerId,
        config: providerConfig,
      );
    }).toList();
    // No need to sort again as _getProvidersForCapability already returns in fallback order
  }

  /// ğŸ—£ï¸ Obtiene las voces disponibles para un proveedor especÃ­fico
  static Future<List<Map<String, dynamic>>> getVoicesForProvider(
    final String providerId,
  ) async {
    await _manager.initialize();
    try {
      final voices = await _manager.getAvailableVoices(providerId);
      return voices;
    } on Exception catch (e) {
      AILogger.w('Error getting voices for provider $providerId: $e');
      return [];
    }
  }
}
