import 'dart:async';
import 'dart:convert';
import 'dart:io';
import 'dart:typed_data';
import 'package:flutter/foundation.dart';
import 'package:record/record.dart';
import '../models/ai_response.dart';
import '../models/transcribe_instructions.dart';
import '../models/ai_capability.dart';
import '../models/ai_system_prompt.dart';
import '../core/ai_provider_manager.dart';
import '../utils/logger.dart';
import '../utils/waveform_utils.dart';

/// üéß AudioTranscriptionService - Servicio completo de transcripci√≥n de audio
///
/// Consolida TODA la funcionalidad de STT/transcripci√≥n:
/// - Transcripci√≥n de archivos usando AI.listen()
/// - Grabaci√≥n de audio con transcripci√≥n en tiempo real
/// - Gesti√≥n de permisos de micr√≥fono
/// - Detecci√≥n autom√°tica de plataforma (m√≥vil vs desktop)
/// - Streams de waveform y transcripci√≥n en vivo
/// - Gesti√≥n inteligente de timeouts y silencios
///
/// Reemplaza stt_service.dart (680 l√≠neas) con funcionalidad consolidada
class AudioTranscriptionService {
  AudioTranscriptionService._();
  static final AudioTranscriptionService _instance =
      AudioTranscriptionService._();
  static AudioTranscriptionService get instance => _instance;

  // Grabaci√≥n
  final AudioRecorder _recorder = AudioRecorder();
  bool _isRecording = false;
  Timer? _recordingTimer;
  Duration _recordingDuration = Duration.zero;

  // Streams
  final StreamController<List<int>> _waveformController =
      StreamController<List<int>>.broadcast();
  final StreamController<String> _transcriptController =
      StreamController<String>.broadcast();
  final StreamController<Duration> _durationController =
      StreamController<Duration>.broadcast();

  // Getters
  bool get isRecording => _isRecording;
  Duration get recordingDuration => _recordingDuration;

  // Streams
  Stream<List<int>> get waveformStream => _waveformController.stream;
  Stream<String> get transcriptStream => _transcriptController.stream;
  Stream<Duration> get durationStream => _durationController.stream;

  /// üéØ M√âTODO DE INTEGRACI√ìN - usado por AI.listen()
  ///
  /// Recibe mismos par√°metros que AI.listen() y delega a AIProviderManager.
  /// Esta es la firma EXACTA que necesita AI.listen() para evitar circular dependency.
  Future<AIResponse> transcribe(
    String audioBase64, [
    TranscribeInstructions? instructions,
  ]) async {
    try {
      AILogger.d('[AudioTranscriptionService] üéß Transcribiendo audio...');

      // Crear SystemPrompt con las instrucciones de transcripci√≥n
      final systemPrompt = _createTranscriptionSystemPrompt(instructions);

      // Llamar directamente a AIProviderManager (no a AI.listen() para evitar circular dependency)
      return await AIProviderManager.instance.sendMessage(
        message:
            'Transcribe the provided audio according to the given instructions',
        systemPrompt: systemPrompt,
        capability: AICapability.audioTranscription,
        imageBase64: audioBase64, // Reutilizamos imageBase64 para audio
      );
    } catch (e) {
      AILogger.e(
          '[AudioTranscriptionService] ‚ùå Error transcribiendo audio: $e');
      rethrow;
    }
  }

  /// Transcribir archivo de audio usando AI.listen()
  Future<AIResponse> transcribeAudioFile(final String filePath) async {
    try {
      AILogger.d(
        '[AudioTranscriptionService] üéß Transcribiendo archivo: $filePath',
      );

      if (!File(filePath).existsSync()) {
        throw Exception('Archivo no existe: $filePath');
      }

      // Leer archivo y convertir a base64
      final audioBytes = await File(filePath).readAsBytes();
      final base64Audio = base64Encode(audioBytes);

      // üöÄ Usar nuestro m√©todo de integraci√≥n (no AI.listen() para evitar circular)
      final response = await transcribe(base64Audio);

      AILogger.d(
        '[AudioTranscriptionService] ‚úÖ Transcripci√≥n completada: ${response.text.length} chars',
      );
      return response;
    } on Exception catch (e) {
      AILogger.e(
        '[AudioTranscriptionService] Error transcribiendo archivo: $e',
      );
      rethrow;
    }
  }

  /// Transcribir audio desde base64
  Future<AIResponse> transcribeAudio(final String audioBase64) async {
    try {
      AILogger.d('[AudioTranscriptionService] üéß Transcribiendo audio base64');
      return await transcribe(audioBase64);
    } on Exception catch (e) {
      AILogger.e('[AudioTranscriptionService] Error transcribiendo base64: $e');
      rethrow;
    }
  }

  /// Transcribir audio desde bytes
  Future<AIResponse> transcribeBytes(final Uint8List audioBytes) async {
    try {
      AILogger.d(
        '[AudioTranscriptionService] üéß Transcribiendo ${audioBytes.length} bytes',
      );
      final base64Audio = base64Encode(audioBytes);
      return await transcribe(base64Audio);
    } on Exception catch (e) {
      AILogger.e('[AudioTranscriptionService] Error transcribiendo bytes: $e');
      rethrow;
    }
  }

  /// Verificar permisos de micr√≥fono
  Future<bool> hasPermissions() async {
    try {
      return await _recorder.hasPermission();
    } on Exception catch (e) {
      AILogger.e('[AudioTranscriptionService] Error verificando permisos: $e');
      return false;
    }
  }

  /// Solicitar permisos de micr√≥fono
  Future<bool> requestPermissions() async {
    try {
      return await _recorder.hasPermission();
    } on Exception catch (e) {
      AILogger.e('[AudioTranscriptionService] Error solicitando permisos: $e');
      return false;
    }
  }

  /// üéØ M√âTODO PRINCIPAL: Grabar y transcribir audio con duraci√≥n espec√≠fica
  /// Este es el m√©todo principal del servicio para funcionalidad completa STT
  Future<String?> recordAndTranscribe(
      {Duration duration = const Duration(seconds: 5)}) async {
    try {
      AILogger.d(
          '[AudioTranscriptionService] üéØ recordAndTranscribe($duration) iniciado');

      // Verificar permisos
      if (!await hasPermissions()) {
        throw Exception('Permisos de micr√≥fono denegados');
      }

      // Iniciar grabaci√≥n
      await startRecording();

      // Esperar la duraci√≥n especificada
      await Future.delayed(duration);

      // Detener y transcribir
      final transcript = await stopRecording();

      AILogger.d(
          '[AudioTranscriptionService] ‚úÖ recordAndTranscribe completado: $transcript');
      return transcript;
    } catch (e) {
      AILogger.e(
          '[AudioTranscriptionService] Error en recordAndTranscribe(): $e');
      await cancelRecording(); // Limpiar en caso de error
      rethrow;
    }
  }

  /// Iniciar grabaci√≥n con transcripci√≥n en tiempo real
  Future<void> startRecording() async {
    try {
      if (_isRecording) {
        AILogger.w(
          '[AudioTranscriptionService] Ya hay una grabaci√≥n en progreso',
        );
        return;
      }

      // Verificar permisos
      if (!await hasPermissions()) {
        throw Exception('Permisos de micr√≥fono denegados');
      }

      AILogger.d('[AudioTranscriptionService] üé§ Iniciando grabaci√≥n...');

      // Configurar grabaci√≥n
      const config = RecordConfig(encoder: AudioEncoder.wav, sampleRate: 16000);

      // Iniciar grabaci√≥n
      await _recorder.start(
        config,
        path:
            '${Directory.systemTemp.path}/recording_${DateTime.now().millisecondsSinceEpoch}.wav',
      );
      _isRecording = true;
      _recordingDuration = Duration.zero;

      // Iniciar timers para waveform y duraci√≥n
      _startRecordingTimers();

      AILogger.d('[AudioTranscriptionService] ‚úÖ Grabaci√≥n iniciada');
    } on Exception catch (e) {
      AILogger.e('[AudioTranscriptionService] Error iniciando grabaci√≥n: $e');
      rethrow;
    }
  }

  /// Detener grabaci√≥n y transcribir
  Future<String?> stopRecording() async {
    try {
      if (!_isRecording) {
        AILogger.w('[AudioTranscriptionService] No hay grabaci√≥n activa');
        return null;
      }

      AILogger.d('[AudioTranscriptionService] ‚èπÔ∏è Deteniendo grabaci√≥n...');

      // Detener grabaci√≥n
      final audioPath = await _recorder.stop();
      _isRecording = false;
      _stopRecordingTimers();

      if (audioPath == null) {
        AILogger.w('[AudioTranscriptionService] No se gener√≥ archivo de audio');
        return null;
      }

      // Transcribir el audio grabado
      AILogger.d(
        '[AudioTranscriptionService] üéß Transcribiendo audio grabado...',
      );
      final response = await transcribeAudioFile(audioPath);

      // Limpiar archivo temporal
      _cleanupAudioFile(audioPath);

      final transcript = response.text.trim();
      AILogger.d(
        '[AudioTranscriptionService] ‚úÖ Transcripci√≥n completada: $transcript',
      );

      return transcript.isNotEmpty ? transcript : null;
    } on Exception catch (e) {
      AILogger.e('[AudioTranscriptionService] Error deteniendo grabaci√≥n: $e');
      _isRecording = false;
      _stopRecordingTimers();
      return null;
    }
  }

  /// Cancelar grabaci√≥n actual
  Future<void> cancelRecording() async {
    try {
      if (!_isRecording) return;

      AILogger.d('[AudioTranscriptionService] üö´ Cancelando grabaci√≥n...');

      await _recorder.stop();
      _isRecording = false;
      _stopRecordingTimers();
      _resetRecordingState();

      AILogger.d('[AudioTranscriptionService] Grabaci√≥n cancelada');
    } on Exception catch (e) {
      AILogger.e('[AudioTranscriptionService] Error cancelando grabaci√≥n: $e');
    }
  }

  // === M√âTODOS PRIVADOS ===

  /// Crea SystemPrompt para transcripci√≥n de audio con instrucciones
  AISystemPrompt _createTranscriptionSystemPrompt(
      TranscribeInstructions? instructions) {
    final effectiveInstructions =
        instructions ?? const TranscribeInstructions();

    final context = <String, dynamic>{
      'task': 'audio_transcription',
      'stt': true,
    };

    return AISystemPrompt(
      context: context,
      dateTime: DateTime.now(),
      instructions: effectiveInstructions.toMap(),
    );
  }

  void _startRecordingTimers() {
    _recordingTimer = Timer.periodic(const Duration(milliseconds: 100), (
      final timer,
    ) {
      _recordingDuration = Duration(
        milliseconds: _recordingDuration.inMilliseconds + 100,
      );
      _durationController.add(_recordingDuration);

      // Generar waveform animado usando utility
      final waveform = WaveformUtils.animateRecordingWaveform(
        _recordingDuration,
      );
      _waveformController.add(waveform);

      // Simular transcripci√≥n en vivo (en implementaci√≥n real vendr√≠a del STT)
      _updateLiveTranscript();
    });
  }

  void _stopRecordingTimers() {
    _recordingTimer?.cancel();
    _recordingTimer = null;
  }

  void _resetRecordingState() {
    _recordingDuration = Duration.zero;
    _durationController.add(Duration.zero);
    _transcriptController.add('');
    _waveformController.add(<int>[]);
  }

  void _updateLiveTranscript() {
    // Actualizar el transcript placeholder durante la grabaci√≥n
    // En implementaci√≥n real, esto vendr√≠a del STT en streaming
    _transcriptController.add('Grabando... ${_recordingDuration.inSeconds}s');
  }

  void _cleanupAudioFile(final String filePath) {
    try {
      final file = File(filePath);
      if (file.existsSync()) {
        file.deleteSync();
        AILogger.d(
          '[AudioTranscriptionService] Archivo temporal limpiado: $filePath',
        );
      }
    } on Exception catch (e) {
      AILogger.w('[AudioTranscriptionService] Error limpiando archivo: $e');
    }
  }

  /// Limpiar recursos
  void dispose() {
    // Cancelar grabaci√≥n si est√° activa
    if (_isRecording) {
      cancelRecording();
    }

    // Cerrar streams
    _waveformController.close();
    _transcriptController.close();
    _durationController.close();

    // Detener timers
    _stopRecordingTimers();

    AILogger.d('[AudioTranscriptionService] Recursos liberados');
  }
}
