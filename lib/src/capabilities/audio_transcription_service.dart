import 'dart:async';
import 'dart:convert';
import 'dart:io';
import 'dart:typed_data';
import 'package:flutter/foundation.dart';
import 'package:record/record.dart';
import '../models/ai_response.dart';
import '../ai.dart';
import '../utils/logger.dart';
import '../utils/waveform_utils.dart';

/// üéß AudioTranscriptionService - Servicio completo de transcripci√≥n de audio
///
/// Consolida TODA la funcionalidad de STT/transcripci√≥n:
/// - Transcripci√≥n de archivos usando AI.transcribe()
/// - Grabaci√≥n de audio con transcripci√≥n en tiempo real
/// - Gesti√≥n de permisos de micr√≥fono
/// - Detecci√≥n autom√°tica de plataforma (m√≥vil vs desktop)
/// - Streams de waveform y transcripci√≥n en vivo
/// - Gesti√≥n inteligente de timeouts y silencios
///
/// Reemplaza stt_service.dart (680 l√≠neas) con funcionalidad consolidada
class AudioTranscriptionService {
  AudioTranscriptionService._();
  static final AudioTranscriptionService _instance =
      AudioTranscriptionService._();
  static AudioTranscriptionService get instance => _instance;

  // Grabaci√≥n
  final AudioRecorder _recorder = AudioRecorder();
  bool _isRecording = false;
  Timer? _recordingTimer;
  Duration _recordingDuration = Duration.zero;

  // Streams
  final StreamController<List<int>> _waveformController =
      StreamController<List<int>>.broadcast();
  final StreamController<String> _transcriptController =
      StreamController<String>.broadcast();
  final StreamController<Duration> _durationController =
      StreamController<Duration>.broadcast();

  // Estado
  String _liveTranscript = '';

  // Getters
  bool get isRecording => _isRecording;
  String get liveTranscript => _liveTranscript;
  Duration get recordingDuration => _recordingDuration;

  // Streams
  Stream<List<int>> get waveformStream => _waveformController.stream;
  Stream<String> get transcriptStream => _transcriptController.stream;
  Stream<Duration> get durationStream => _durationController.stream;

  /// Transcribir archivo de audio usando AI.transcribe()
  Future<AIResponse> transcribeAudioFile(final String filePath) async {
    try {
      AILogger.d(
        '[AudioTranscriptionService] üéß Transcribiendo archivo: $filePath',
      );

      if (!File(filePath).existsSync()) {
        throw Exception('Archivo no existe: $filePath');
      }

      // Leer archivo y convertir a base64
      final audioBytes = await File(filePath).readAsBytes();
      final base64Audio = base64Encode(audioBytes);

      // üöÄ Usar nueva API AI.transcribe()
      final response = await AI.transcribe(base64Audio);

      AILogger.d(
        '[AudioTranscriptionService] ‚úÖ Transcripci√≥n completada: ${response.text.length} chars',
      );
      return response;
    } on Exception catch (e) {
      AILogger.e(
        '[AudioTranscriptionService] Error transcribiendo archivo: $e',
      );
      rethrow;
    }
  }

  /// Transcribir audio desde base64
  Future<AIResponse> transcribeAudio(final String audioBase64) async {
    try {
      AILogger.d('[AudioTranscriptionService] üéß Transcribiendo audio base64');
      return await AI.transcribe(audioBase64);
    } on Exception catch (e) {
      AILogger.e('[AudioTranscriptionService] Error transcribiendo base64: $e');
      rethrow;
    }
  }

  /// Transcribir audio desde bytes
  Future<AIResponse> transcribeBytes(final Uint8List audioBytes) async {
    try {
      AILogger.d(
        '[AudioTranscriptionService] üéß Transcribiendo ${audioBytes.length} bytes',
      );
      final base64Audio = base64Encode(audioBytes);
      return await AI.transcribe(base64Audio);
    } on Exception catch (e) {
      AILogger.e('[AudioTranscriptionService] Error transcribiendo bytes: $e');
      rethrow;
    }
  }

  /// Verificar permisos de micr√≥fono
  Future<bool> hasPermissions() async {
    try {
      return await _recorder.hasPermission();
    } on Exception catch (e) {
      AILogger.e('[AudioTranscriptionService] Error verificando permisos: $e');
      return false;
    }
  }

  /// Solicitar permisos de micr√≥fono
  Future<bool> requestPermissions() async {
    try {
      return await _recorder.hasPermission();
    } on Exception catch (e) {
      AILogger.e('[AudioTranscriptionService] Error solicitando permisos: $e');
      return false;
    }
  }

  /// Iniciar grabaci√≥n con transcripci√≥n en tiempo real
  Future<void> startRecording() async {
    try {
      if (_isRecording) {
        AILogger.w(
          '[AudioTranscriptionService] Ya hay una grabaci√≥n en progreso',
        );
        return;
      }

      // Verificar permisos
      if (!await hasPermissions()) {
        throw Exception('Permisos de micr√≥fono denegados');
      }

      AILogger.d('[AudioTranscriptionService] üé§ Iniciando grabaci√≥n...');

      // Configurar grabaci√≥n
      const config = RecordConfig(encoder: AudioEncoder.wav, sampleRate: 16000);

      // Iniciar grabaci√≥n
      await _recorder.start(
        config,
        path:
            '${Directory.systemTemp.path}/recording_${DateTime.now().millisecondsSinceEpoch}.wav',
      );
      _isRecording = true;
      _recordingDuration = Duration.zero;

      // Iniciar timers para waveform y duraci√≥n
      _startRecordingTimers();

      AILogger.d('[AudioTranscriptionService] ‚úÖ Grabaci√≥n iniciada');
    } on Exception catch (e) {
      AILogger.e('[AudioTranscriptionService] Error iniciando grabaci√≥n: $e');
      rethrow;
    }
  }

  /// Detener grabaci√≥n y transcribir
  Future<String?> stopRecording() async {
    try {
      if (!_isRecording) {
        AILogger.w('[AudioTranscriptionService] No hay grabaci√≥n activa');
        return null;
      }

      AILogger.d('[AudioTranscriptionService] ‚èπÔ∏è Deteniendo grabaci√≥n...');

      // Detener grabaci√≥n
      final audioPath = await _recorder.stop();
      _isRecording = false;
      _stopRecordingTimers();

      if (audioPath == null) {
        AILogger.w('[AudioTranscriptionService] No se gener√≥ archivo de audio');
        return null;
      }

      // Transcribir el audio grabado
      AILogger.d(
        '[AudioTranscriptionService] üéß Transcribiendo audio grabado...',
      );
      final response = await transcribeAudioFile(audioPath);

      // Limpiar archivo temporal
      _cleanupAudioFile(audioPath);

      final transcript = response.text.trim();
      AILogger.d(
        '[AudioTranscriptionService] ‚úÖ Transcripci√≥n completada: $transcript',
      );

      return transcript.isNotEmpty ? transcript : null;
    } on Exception catch (e) {
      AILogger.e('[AudioTranscriptionService] Error deteniendo grabaci√≥n: $e');
      _isRecording = false;
      _stopRecordingTimers();
      return null;
    }
  }

  /// Cancelar grabaci√≥n actual
  Future<void> cancelRecording() async {
    try {
      if (!_isRecording) return;

      AILogger.d('[AudioTranscriptionService] üö´ Cancelando grabaci√≥n...');

      await _recorder.stop();
      _isRecording = false;
      _stopRecordingTimers();
      _resetRecordingState();

      AILogger.d('[AudioTranscriptionService] Grabaci√≥n cancelada');
    } on Exception catch (e) {
      AILogger.e('[AudioTranscriptionService] Error cancelando grabaci√≥n: $e');
    }
  }

  // === M√âTODOS PRIVADOS ===

  void _startRecordingTimers() {
    _recordingTimer = Timer.periodic(const Duration(milliseconds: 100), (
      final timer,
    ) {
      _recordingDuration = Duration(
        milliseconds: _recordingDuration.inMilliseconds + 100,
      );
      _durationController.add(_recordingDuration);

      // Generar waveform animado usando utility
      final waveform = WaveformUtils.animateRecordingWaveform(
        _recordingDuration,
      );
      _waveformController.add(waveform);

      // Simular transcripci√≥n en vivo (en implementaci√≥n real vendr√≠a del STT)
      _updateLiveTranscript();
    });
  }

  void _stopRecordingTimers() {
    _recordingTimer?.cancel();
    _recordingTimer = null;
  }

  void _resetRecordingState() {
    _recordingDuration = Duration.zero;
    _liveTranscript = '';
    _durationController.add(Duration.zero);
    _transcriptController.add('');
    _waveformController.add(<int>[]);
  }

  void _updateLiveTranscript() {
    // En implementaci√≥n real, esto vendr√≠a del STT en tiempo real
    // Por ahora es un placeholder que simula palabras apareciendo
    if (_recordingDuration.inSeconds > 1 &&
        _recordingDuration.inSeconds % 2 == 0) {
      _liveTranscript +=
          _recordingDuration.inSeconds <= 5 ? 'transcribiendo... ' : '';
      _transcriptController.add(_liveTranscript);
    }
  }

  void _cleanupAudioFile(final String filePath) {
    try {
      final file = File(filePath);
      if (file.existsSync()) {
        file.deleteSync();
        AILogger.d(
          '[AudioTranscriptionService] Archivo temporal limpiado: $filePath',
        );
      }
    } on Exception catch (e) {
      AILogger.w('[AudioTranscriptionService] Error limpiando archivo: $e');
    }
  }

  /// Limpiar recursos
  void dispose() {
    // Cancelar grabaci√≥n si est√° activa
    if (_isRecording) {
      cancelRecording();
    }

    // Cerrar streams
    _waveformController.close();
    _transcriptController.close();
    _durationController.close();

    // Detener timers
    _stopRecordingTimers();

    AILogger.d('[AudioTranscriptionService] Recursos liberados');
  }
}
