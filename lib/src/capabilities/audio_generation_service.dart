import 'dart:async';
import 'dart:io';

import 'package:flutter_tts/flutter_tts.dart';
import 'package:audioplayers/audioplayers.dart';

import '../../ai_providers.dart';
import '../core/ai_provider_manager.dart';
import '../utils/logger.dart';

/// üé§ AudioGenerationService - Servicio completo de generaci√≥n de audio
///
/// Consolida TODA la funcionalidad de TTS/audio en un solo lugar:
/// - S√≠ntesis de texto a voz usando AI.speak()
/// - Cache inteligente de TTS
/// - Gesti√≥n de archivos temporales
/// - Reproducci√≥n de audio
/// - Control de estado de reproducci√≥n
///
/// Reemplaza audio_service.dart (549 l√≠neas) con funcionalidad consolidada
class AudioGenerationService {
  // Constructor privado con inicializaci√≥n
  AudioGenerationService._() {
    _initializeTts();
    _initializeAudioPlayer();
  }
  // Sistema de reproducci√≥n REAL usando flutter_tts
  late FlutterTts _flutterTts;
  final StreamController<AudioPlaybackState> _playbackStateController =
      StreamController<AudioPlaybackState>.broadcast();
  AudioPlaybackState _currentState = AudioPlaybackState.idle;

  // AudioPlayer para archivos reales
  AudioPlayer? _audioPlayer;
  StreamSubscription<PlayerState>? _playerStateSubscription;

  // Rastrear qu√© tipo de reproducci√≥n est√° activa
  bool _isPlayingFile = false;

  // Streams p√∫blicos para estado de reproducci√≥n
  Stream<AudioPlaybackState> get playbackStateStream =>
      _playbackStateController.stream;
  AudioPlaybackState get playbackState => _currentState;
  bool get isPlaying => _currentState == AudioPlaybackState.playing;

  static final AudioGenerationService _instance = AudioGenerationService._();
  static AudioGenerationService get instance => _instance;

  /// üéØ M√âTODO SIMPLE - usado por AI.speak()
  ///
  /// Versi√≥n simple que siempre guarda en cach√© para m√°xima facilidad de uso.
  /// Esta es la firma EXACTA que necesita AI.speak() para evitar circular dependency.
  Future<AIResponse> synthesize(
    final String text, [
    final AiAudioParams? audioParams,
    final bool play = false,
  ]) async {
    try {
      AILogger.d(
          '[AudioGenerationService] üé§ Sintetizando audio: ${text.substring(0, text.length.clamp(0, 50))}...');

      // Crear SystemPrompt con par√°metros de audio
      final systemPrompt = _createSynthesizeSystemPrompt(audioParams);

      // Llamar directamente a AIProviderManager - siempre guarda en cach√© para m√°xima flexibilidad
      final response = await AIProviderManager.instance.sendMessage(
        message: text,
        systemPrompt: systemPrompt,
        capability: AICapability.audioGeneration,
        additionalParams: audioParams?.toMap(),
        saveToCache: true,
      );

      // Si play=true, reproducir autom√°ticamente el audio generado
      if (play && response.audioFileName.isNotEmpty) {
        unawaited(playAudioFile(response.audioFileName));
      }

      return response;
    } catch (e) {
      AILogger.e('[AudioGenerationService] ‚ùå Error sintetizando audio: $e');
      rethrow;
    }
  }

  /// üé® M√âTODO AVANZADO - Con control completo de configuraci√≥n
  ///
  /// Permite control total sobre par√°metros de audio, cach√© y reproducci√≥n autom√°tica.
  /// Para uso avanzado cuando se necesita control espec√≠fico.
  Future<AIResponse> synthesizeAdvanced(
    final String text, {
    final AiAudioParams? audioParams,
    final bool saveToCache = true,
    final bool play = false,
  }) async {
    try {
      AILogger.d(
          '[AudioGenerationService] üé® Sintetizando audio (avanzado): ${text.substring(0, text.length.clamp(0, 50))}... (saveToCache: $saveToCache, play: $play)');

      // Crear SystemPrompt con par√°metros de audio
      final systemPrompt = _createSynthesizeSystemPrompt(audioParams);

      // Llamar directamente a AIProviderManager con control completo
      final response = await AIProviderManager.instance.sendMessage(
        message: text,
        systemPrompt: systemPrompt,
        capability: AICapability.audioGeneration,
        additionalParams: audioParams?.toMap(),
        saveToCache: saveToCache,
      );

      // Si play=true, reproducir autom√°ticamente el audio generado
      if (play && response.audioFileName.isNotEmpty) {
        unawaited(playAudioFile(response.audioFileName));
      }

      return response;
    } catch (e) {
      AILogger.e('[AudioGenerationService] ‚ùå Error en synthesizeAdvanced: $e');
      rethrow;
    }
  }

  /// Genera audio/TTS simplificado (wrapper para compatibilidad)
  /// DEPRECATED: Usar synthesize() directamente
  Future<String?> synthesizeTts(
    final String text, {
    final String? languageCode,
    final bool forDialogDemo = false,
  }) async {
    try {
      if (text.trim().isEmpty) {
        AILogger.w('[AudioGenerationService] Texto vac√≠o para TTS');
        return null;
      }

      // Usar synthesize() directamente - m√°s eficiente y sin duplicaci√≥n
      final response = await synthesize(text);

      return response.audioFileName.isNotEmpty ? response.audioFileName : null;
    } on Exception catch (e) {
      AILogger.e('[AudioGenerationService] Error generando TTS: $e');
      return null;
    }
  }

  /// Inicializar TTS con callbacks
  void _initializeTts() {
    _flutterTts = FlutterTts();
    _setupTtsHandlers();
  }

  /// Configurar handlers de TTS
  void _setupTtsHandlers() {
    _flutterTts.setStartHandler(() {
      _updateState(AudioPlaybackState.playing);
      AILogger.d('[AudioGenerationService] TTS iniciado');
    });

    _flutterTts.setCompletionHandler(() {
      _updateState(AudioPlaybackState.completed);
      AILogger.d('[AudioGenerationService] TTS completado');
    });

    _flutterTts.setErrorHandler((final msg) {
      _updateState(AudioPlaybackState.error);
      AILogger.e('[AudioGenerationService] Error TTS: $msg');
    });
  }

  /// Sintetizar y reproducir inmediatamente (wrapper para compatibilidad)
  /// DEPRECATED: Usar synthesize(text, audioParams, play: true) directamente
  Future<bool> synthesizeAndPlay(
    final String text, {
    final String? languageCode,
  }) async {
    try {
      AILogger.d(
          '[AudioGenerationService] üé§üîä SynthesizeAndPlay: ${text.substring(0, text.length.clamp(0, 50))}...');

      // Crear par√°metros b√°sicos si se especifica idioma (compatibilidad)
      final audioParams =
          languageCode != null ? AiAudioParams(language: languageCode) : null;

      // Usar synthesize() con play=true - m√°s eficiente y sin duplicaci√≥n
      final response = await synthesize(text, audioParams, true);

      return response.audioFileName.isNotEmpty;
    } on Exception catch (e) {
      AILogger.e('[AudioGenerationService] Error en synthesizeAndPlay: $e');
      _updateState(AudioPlaybackState.error);
      return false;
    }
  }

  /// Reproducir archivo de audio (archivos reales de providers IA)
  Future<bool> playAudioFile(final String fileName) async {
    try {
      AILogger.d(
          '[AudioGenerationService] üîä Reproduciendo archivo: $fileName');

      // Construct full path for audio files
      String fullPath;
      if (fileName.startsWith('/')) {
        // Already a full path
        fullPath = fileName;
      } else {
        // Construct path using MediaPersistenceService - need to get audio directory
        // For now, use the standard temp cache path
        fullPath = '/tmp/ai_providers_cache/audio/$fileName';
      }

      if (!File(fullPath).existsSync()) {
        AILogger.w('[AudioGenerationService] Archivo no existe: $fullPath');
        return false;
      }

      _updateState(AudioPlaybackState.loading);

      // Use AudioPlayer for real file playback
      return await _playWithAudioPlayer(fullPath);
    } on Exception catch (e) {
      AILogger.e('[AudioGenerationService] Error reproduciendo archivo: $e');
      _updateState(AudioPlaybackState.error);
      return false;
    }
  }

  /// Detener reproducci√≥n
  Future<bool> stopPlayback() async {
    try {
      bool success = true;

      if (_isPlayingFile) {
        // Stop AudioPlayer if playing a file
        if (_audioPlayer != null) {
          await _audioPlayer!.stop();
          AILogger.d('[AudioGenerationService] AudioPlayer detenido');
        }
      } else {
        // Stop TTS if playing via flutter_tts
        final ttsResult = await _flutterTts.stop();
        if (ttsResult != 1) success = false;
      }

      _isPlayingFile = false;
      _updateState(AudioPlaybackState.stopped);
      AILogger.d('[AudioGenerationService] Reproducci√≥n detenida');
      return success;
    } on Exception catch (e) {
      AILogger.e('[AudioGenerationService] Error deteniendo: $e');
      return false;
    }
  }

  /// Pausar reproducci√≥n
  Future<bool> pausePlayback() async {
    try {
      bool success = true;

      if (_isPlayingFile) {
        // Pause AudioPlayer if playing a file
        if (_audioPlayer != null) {
          await _audioPlayer!.pause();
          AILogger.d('[AudioGenerationService] AudioPlayer pausado');
        }
      } else {
        // Pause TTS if playing via flutter_tts
        final result = await _flutterTts.pause();
        success = result == 1;
      }

      _updateState(AudioPlaybackState.paused);
      AILogger.d('[AudioGenerationService] Reproducci√≥n pausada');
      return success;
    } on Exception catch (e) {
      AILogger.e('[AudioGenerationService] Error pausando: $e');
      return false;
    }
  }

  // === M√âTODOS PRIVADOS ===

  /// Crea SystemPrompt para s√≠ntesis de audio con par√°metros tipados
  AISystemPrompt _createSynthesizeSystemPrompt(
      final AiAudioParams? audioParams) {
    final effectiveParams = audioParams ?? const AiAudioParams();

    final context = <String, dynamic>{
      'task': 'audio_generation',
      'tts': true,
    };

    // Combinar contexto con par√°metros de audio para m√°xima informaci√≥n
    final instructions = <String, dynamic>{
      ...context,
      ...effectiveParams.toMap(),
    };

    return AISystemPrompt(
      context: context,
      dateTime: DateTime.now(),
      instructions: instructions,
    );
  }

  /// Actualizar estado de reproducci√≥n
  void _updateState(final AudioPlaybackState newState) {
    _currentState = newState;
    _playbackStateController.add(newState);
    AILogger.d('[AudioGenerationService] Estado: $newState');
  }

  /// Inicializar AudioPlayer
  void _initializeAudioPlayer() {
    try {
      _audioPlayer = AudioPlayer();
      _setupAudioPlayerHandlers();
      AILogger.i(
          '[AudioGenerationService] ‚úÖ AudioPlayer inicializado correctamente');
    } on Exception catch (e) {
      AILogger.w(
          '[AudioGenerationService] ‚ö†Ô∏è  Error inicializando AudioPlayer: $e');
    }
  }

  /// Configurar handlers de AudioPlayer
  void _setupAudioPlayerHandlers() {
    if (_audioPlayer == null) return;

    _playerStateSubscription =
        _audioPlayer!.onPlayerStateChanged.listen((final PlayerState state) {
      switch (state) {
        case PlayerState.playing:
          _updateState(AudioPlaybackState.playing);
          break;
        case PlayerState.paused:
          _updateState(AudioPlaybackState.paused);
          break;
        case PlayerState.stopped:
          _isPlayingFile = false;
          _updateState(AudioPlaybackState.stopped);
          break;
        case PlayerState.completed:
          _isPlayingFile = false;
          _updateState(AudioPlaybackState.completed);
          break;
        case PlayerState.disposed:
          _isPlayingFile = false;
          _updateState(AudioPlaybackState.idle);
          break;
      }
    });
  }

  /// Reproducir con AudioPlayer real
  Future<bool> _playWithAudioPlayer(final String fullPath) async {
    try {
      if (_audioPlayer == null) {
        _initializeAudioPlayer();
      }

      if (_audioPlayer == null) {
        AILogger.e('[AudioGenerationService] AudioPlayer no disponible');
        return false;
      }

      _updateState(AudioPlaybackState.loading);

      // Mark that we're playing a file (not TTS)
      _isPlayingFile = true;

      // Play the audio file
      await _audioPlayer!.play(DeviceFileSource(fullPath));

      AILogger.i(
          '[AudioGenerationService] üéµ Reproduciendo con AudioPlayer: $fullPath');
      return true;
    } on Exception catch (e) {
      AILogger.e('[AudioGenerationService] Error con AudioPlayer: $e');
      _updateState(AudioPlaybackState.error);
      return false;
    }
  }

  /// Limpiar recursos
  void dispose() {
    _flutterTts.stop();
    _playerStateSubscription?.cancel();
    _audioPlayer?.dispose();
    _playbackStateController.close();
    AILogger.d('[AudioGenerationService] Recursos liberados');
  }
}

/// Estados de reproducci√≥n de audio para SDK
enum AudioPlaybackState {
  idle,
  loading,
  playing,
  paused,
  stopped,
  completed,
  error
}
