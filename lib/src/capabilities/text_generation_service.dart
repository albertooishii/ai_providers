import 'package:ai_providers/ai_providers.dart';
import '../core/ai_provider_manager.dart';
import '../utils/logger.dart';

/// Servicio para generaci√≥n de texto con manejo inteligente de SystemPrompt
///
/// Este servicio es la capa intermedia entre AI.text() y AIProviderManager,
/// siguiendo la nueva arquitectura donde Services manejan l√≥gica espec√≠fica.
class TextGenerationService {
  // Singleton pattern consistente con otros services
  TextGenerationService._internal();
  static final TextGenerationService _instance =
      TextGenerationService._internal();
  static TextGenerationService get instance => _instance;

  /// M√©todo de integraci√≥n principal - usado por AI.text()
  ///
  /// Recibe mismos par√°metros que AI.text() y delega a AIProviderManager.
  /// Esta es la firma EXACTA que necesita AI.text() para evitar circular dependency.
  Future<AIResponse> generate(
    String message,
    AISystemPrompt systemPrompt,
  ) async {
    try {
      AILogger.d(
          '[TextGenerationService] ü§ñ Generando texto: ${message.substring(0, message.length.clamp(0, 50))}...');

      // Llamar directamente a AIProviderManager (no a AI.text() para evitar circular dependency)
      return await AIProviderManager.instance.sendMessage(
        message: message,
        systemPrompt: systemPrompt,
        capability: AICapability.textGeneration,
      );
    } catch (e) {
      AILogger.e('[TextGenerationService] ‚ùå Error generando texto: $e');
      rethrow;
    }
  }

  /// Genera texto con SystemPrompt por defecto - para casos donde se omite
  Future<AIResponse> generateWithDefaults(
    String message, {
    Map<String, dynamic>? context,
    List<Map<String, dynamic>>? conversationHistory,
  }) async {
    try {
      AILogger.d('[TextGenerationService] üîß Generando con defaults...');

      final systemPrompt = _createDefaultTextSystemPrompt(
        context: context,
        conversationHistory: conversationHistory,
      );

      return await generate(message, systemPrompt);
    } catch (e) {
      AILogger.e('[TextGenerationService] ‚ùå Error generando con defaults: $e');
      rethrow;
    }
  }

  /// Genera conversaci√≥n con historial - para uso avanzado
  Future<AIResponse> generateWithHistory(
    String message, {
    AISystemPrompt? systemPrompt,
    List<Map<String, dynamic>>? conversationHistory,
  }) async {
    try {
      AILogger.d('[TextGenerationService] üí¨ Generando con historial...');

      final effectiveSystemPrompt = systemPrompt ??
          _createDefaultTextSystemPrompt(
              conversationHistory: conversationHistory);

      // A√±adir historial al systemPrompt
      final systemPromptWithHistory = effectiveSystemPrompt.copyWith(
        history: conversationHistory,
      );

      return await generate(message, systemPromptWithHistory);
    } catch (e) {
      AILogger.e('[TextGenerationService] ‚ùå Error generando con historial: $e');
      rethrow;
    }
  }

  /// Crea SystemPrompt por defecto optimizado para generaci√≥n de texto
  AISystemPrompt _createDefaultTextSystemPrompt({
    Map<String, dynamic>? context,
    List<Map<String, dynamic>>? conversationHistory,
  }) {
    final defaultContext = <String, dynamic>{
      'task': 'text_generation',
      'language': 'spanish',
      'tone': 'helpful_and_professional',
    };

    // Merge context if provided
    if (context != null) {
      defaultContext.addAll(context);
    }

    // Add chat mode if history exists
    if (conversationHistory != null && conversationHistory.isNotEmpty) {
      defaultContext['chat_mode'] = true;
      defaultContext['conversation_context'] = 'maintain_coherent_dialogue';
    }

    final instructions = <String, dynamic>{
      'role':
          'Eres un asistente de IA √∫til que genera texto de alta calidad en espa√±ol.',
      'style': 'Responde de manera clara, precisa y √∫til.',
      'format': 'Usa markdown para formatear respuestas cuando sea apropiado.',
    };

    return AISystemPrompt(
      context: defaultContext,
      dateTime: DateTime.now(),
      instructions: instructions,
      history: conversationHistory,
    );
  }
}
